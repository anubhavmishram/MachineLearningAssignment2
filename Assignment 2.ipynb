{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n",
      "(50,)\n",
      "(100, 2)\n",
      "(100,)\n",
      "2\n",
      "(50, 1)\n",
      "5637.863550197509\n",
      "Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "file_x_test = np.loadtxt('X_test.csv')\n",
    "file_y_test = np.loadtxt('Y_test.csv')\n",
    "file_x_train = np.loadtxt('X_train.csv')\n",
    "file_y_train = np.loadtxt('Y_train.csv')\n",
    "\n",
    "print(file_x_test.shape)\n",
    "print(file_y_test.shape)\n",
    "print(file_x_train.shape)\n",
    "print(file_y_train.shape)\n",
    "\n",
    "file_y_test = file_y_test.reshape(50,1)\n",
    "file_y_train = file_y_train.reshape(100,1)\n",
    "# defining the Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "def softmax(x, derivative=False):\n",
    "        # Numerically stable with large exponentials\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps,axis=0)\n",
    "\n",
    "# initializing the variables\n",
    "epoch=10000 # number of training iterations\n",
    "inputlayer_neurons = file_x_train.shape[1] # number of features in data set\n",
    "print(file_x_train.shape[1])\n",
    "hiddenlayer_neurons = 10 # number of hidden layers neurons\n",
    "output_neurons = 1 # number of neurons at output layer\n",
    "\n",
    "# initializing weight and bias\n",
    "\n",
    "\n",
    "# training the model\n",
    "def model(input_data,output_data,lr):\n",
    "    \n",
    "    wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))*np.sqrt(1./hiddenlayer_neurons)\n",
    "    bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "    wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))*np.sqrt(1./output_neurons)\n",
    "    bout=np.random.uniform(size=(1,output_neurons))\n",
    "    for i in range(epoch):\n",
    "\n",
    "        #Forward Propogation\n",
    "        hidden_layer_input1=np.dot(input_data,wh)\n",
    "        hidden_layer_input=hidden_layer_input1 + bh\n",
    "        hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "        output_layer_input1=np.dot(hiddenlayer_activations,wout)\n",
    "        output_layer_input= output_layer_input1+ bout\n",
    "        output = softmax(output_layer_input)\n",
    "\n",
    "        #Backpropagation\n",
    "        E = output_data-output\n",
    "        slope_output_layer = softmax(output, derivative=True)\n",
    "        slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "        d_output = E * slope_output_layer\n",
    "        Error_at_hidden_layer = d_output.dot(wout.T)\n",
    "        d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "        wout += hiddenlayer_activations.T.dot(d_output) *lr\n",
    "        bout += np.sum(d_output, axis=0,keepdims=True) *lr\n",
    "        wh += input_data.T.dot(d_hiddenlayer) *lr\n",
    "        bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr\n",
    "\n",
    "    return wh,bh,wout,bout\n",
    "\n",
    "final_weights, final_bias, final_weights2,final_bas2= model(file_x_train,file_y_train,0.001)\n",
    "# model(file_x_test,file_y_test,lr=0.001)\n",
    "\n",
    "def predict(input_data, wh,bh,wh2,bh2):\n",
    "    for i in range(epoch):\n",
    "\n",
    "        #Forward Propogation\n",
    "        hidden_layer_input1=np.dot(input_data,wh)\n",
    "        hidden_layer_input=hidden_layer_input1 + bh\n",
    "        hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "        output_layer_input1=np.dot(hiddenlayer_activations,wh2)\n",
    "        output_layer_input= output_layer_input1+ bh2\n",
    "        output = softmax(output_layer_input)\n",
    "    return output\n",
    "\n",
    "predicted_output = predict(file_x_test, final_weights, final_bias,final_weights2,final_bas2)\n",
    "print(predicted_output.shape)\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred,2))\n",
    "\n",
    "print(mse(file_y_test,predicted_output))\n",
    "\n",
    "def compute_accuracy(x_val, y_val,wh,bh,bh2,wh2):\n",
    "    predictions = []\n",
    "    output = predict(x_val,wh,bh,wh2,bh2)\n",
    "    for x, y in zip(output, y_val):\n",
    "        pred = np.argmax(output)\n",
    "        predictions.append(pred == np.argmax(y))\n",
    "    return np.mean(predictions)\n",
    "\n",
    "print(\"Accuracy\",compute_accuracy(file_x_test,file_y_test,final_weights,final_bias,final_bas2,final_weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011 0.0\n",
      "0.020999999999999998 0.0\n",
      "0.031 0.0\n",
      "0.041 0.0\n",
      "0.051000000000000004 0.0\n",
      "0.061000000000000006 0.0\n",
      "0.07100000000000001 0.0\n",
      "0.081 0.0\n",
      "0.091 0.0\n",
      "0.10099999999999999 0.0\n",
      "0.11099999999999999 0.0\n",
      "0.12099999999999998 0.0\n",
      "0.13099999999999998 0.0\n",
      "0.141 0.0\n",
      "0.151 0.0\n",
      "0.161 0.0\n",
      "0.171 0.0\n",
      "0.18100000000000002 0.0\n",
      "0.19100000000000003 0.0\n",
      "0.20100000000000004 0.0\n",
      "0.21100000000000005 0.0\n",
      "0.22100000000000006 0.0\n",
      "0.23100000000000007 0.0\n",
      "0.24100000000000008 0.0\n",
      "0.25100000000000006 0.0\n",
      "0.26100000000000007 0.0\n",
      "0.2710000000000001 0.0\n",
      "0.2810000000000001 0.0\n",
      "0.2910000000000001 0.0\n",
      "0.3010000000000001 0.0\n",
      "0.3110000000000001 0.0\n",
      "0.3210000000000001 0.0\n",
      "0.3310000000000001 0.0\n",
      "0.34100000000000014 0.0\n",
      "0.35100000000000015 0.0\n",
      "0.36100000000000015 0.0\n",
      "0.37100000000000016 0.0\n",
      "0.38100000000000017 0.0\n",
      "0.3910000000000002 0.0\n",
      "0.4010000000000002 0.0\n",
      "0.4110000000000002 0.0\n",
      "0.4210000000000002 0.0\n",
      "0.4310000000000002 0.0\n",
      "0.4410000000000002 0.0\n",
      "0.45100000000000023 0.0\n",
      "0.46100000000000024 0.0\n",
      "0.47100000000000025 0.0\n",
      "0.48100000000000026 0.0\n",
      "0.49100000000000027 0.0\n",
      "0.5010000000000002 0.0\n",
      "0.5110000000000002 0.0\n",
      "0.5210000000000002 0.0\n",
      "0.5310000000000002 0.0\n",
      "0.5410000000000003 0.0\n",
      "0.5510000000000003 0.0\n",
      "0.5610000000000003 0.0\n",
      "0.5710000000000003 0.0\n",
      "0.5810000000000003 0.0\n",
      "0.5910000000000003 0.0\n",
      "0.6010000000000003 0.0\n",
      "0.6110000000000003 0.0\n",
      "0.6210000000000003 0.0\n",
      "0.6310000000000003 0.0\n",
      "0.6410000000000003 0.0\n",
      "0.6510000000000004 0.0\n",
      "0.6610000000000004 0.0\n",
      "0.6710000000000004 0.0\n",
      "0.6810000000000004 0.0\n",
      "0.6910000000000004 0.0\n",
      "0.7010000000000004 0.0\n",
      "0.7110000000000004 0.0\n",
      "0.7210000000000004 0.0\n",
      "0.7310000000000004 0.0\n",
      "0.7410000000000004 0.0\n",
      "0.7510000000000004 0.0\n",
      "0.7610000000000005 0.0\n",
      "0.7710000000000005 0.0\n",
      "0.7810000000000005 0.0\n",
      "0.7910000000000005 0.0\n",
      "0.8010000000000005 0.0\n",
      "0.8110000000000005 0.0\n",
      "0.8210000000000005 0.0\n",
      "0.8310000000000005 0.0\n",
      "0.8410000000000005 0.0\n",
      "0.8510000000000005 0.0\n",
      "0.8610000000000005 0.0\n",
      "0.8710000000000006 0.0\n",
      "0.8810000000000006 0.0\n",
      "0.8910000000000006 0.0\n",
      "0.9010000000000006 0.0\n",
      "0.9110000000000006 0.0\n",
      "0.9210000000000006 0.0\n",
      "0.9310000000000006 0.0\n",
      "0.9410000000000006 0.0\n",
      "0.9510000000000006 0.0\n",
      "0.9610000000000006 0.0\n",
      "0.9710000000000006 0.0\n",
      "0.9810000000000006 0.0\n",
      "0.9910000000000007 0.0\n",
      "1.0010000000000006 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2042040c490>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 0.001\n",
    "accu = []\n",
    "lrs = []\n",
    "while x < 1.0 :\n",
    "    x = x + 0.010\n",
    "    final_weights, final_bias, final_weights2,final_bas2= model(file_x_train,file_y_train,0.001)\n",
    "    predicted_output = predict(file_x_test, final_weights, final_bias,final_weights2,final_bas2)\n",
    "    pert = compute_accuracy(file_x_test,file_y_test,final_weights,final_bias,final_bas2,final_weights2)\n",
    "    accu.append(pert)\n",
    "    lrs.append(x)\n",
    "    print(x,pert)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lrs,accu)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "    dt=1-t**2\n",
    "    return t,dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
